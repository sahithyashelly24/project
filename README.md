# ğŸ§  Cognitive Vox

> An intelligent audio analysis system to detect emotions and predict therapy needs â€” built with deep learning and care.

---

## ğŸ“Œ About the Project

**Cognitive Vox** is a voice-based emotional analysis and therapy prediction system. Users can upload or record their voice, and the app will:

1. **Transcribe** the audio using Whisper.
2. **Analyze emotions** using a Vision Transformer (ViT) trained on spectrograms.
3. **Predict** the number of therapy sessions required based on the emotions, userâ€™s age, and gender.
4. **Track** emotional changes over time using visualizations.

This project is designed to assist in mental health awareness and provide helpful insights from just a voice sample.

---

## ğŸ§­ Architecture Overview

![System Architecture](./assets/cognitive_vox_architecture.png)

> The above diagram shows the complete pipeline â€” from audio input to transcription, emotion classification, and therapy prediction â€” built with FastAPI and machine learning models.

---

## âœ¨ Features

- ğŸ¤ **Audio Input**: Upload or record voice.
- ğŸ§  **Emotion Detection**: Classifies emotions like Happy, Sadness, Anger, Anxiety, etc.
- ğŸ“ƒ **Speech Transcription**: Converts speech to text using Whisper.
- ğŸ”® **Therapy Prediction**: Estimates how many sessions a user may need.
- ğŸ“Š **Emotion History Tracking**: Visual display of progress over time.
- ğŸ‘©â€âš•ï¸ **Personalized Analysis**: Takes userâ€™s gender and age into account for predictions.

---

## ğŸ›  Tech Stack

| Layer        | Tools/Libraries Used                                     |
|--------------|-----------------------------------------------------------|
| Frontend     | React.js (with charts and user profile UI)               |
| Backend      | FastAPI                                                  |
| ML Models    | ViT (`timm`), Random Forest, XGBoost, Gradient Boost     |
| Audio Tools  | Whisper, Torchaudio, PyDub, librosa                      |
| Dataset      | RAVDESS (processed into spectrograms)                   |

---

## ğŸ§ª Machine Learning Models

### ğŸ¨ Emotion Recognition (ViT)

- **Input**: Audio converted to spectrograms
- **Model**: Vision Transformer (ViT)
- **Trained On**: RAVDESS dataset (10 custom emotions)
- **Emotions Detected**:
  - Happy
  - Sadness
  - Anger
  - Anxiety
  - Calmness
  - Frustration
  - Hope
  - Confusion
  - Comfort
  - Peace

### ğŸ”® Therapy Session Predictor

- **Model Type**: Ensemble (Random Forest, XGBoost, Gradient Boost)
- **Inputs**: Emotion scores, userâ€™s age, gender
- **Output**: Number of therapy sessions recommended

---
